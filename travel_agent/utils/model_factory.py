"""
Model Factory - ç»Ÿä¸€çš„LLMæ¨¡å‹åˆ›å»ºå·¥å…·
æä¾›ç»Ÿä¸€çš„ModelScopeæ¨¡å‹åˆ›å»ºé€»è¾‘ï¼Œé¿å…é‡å¤ä»£ç 
"""

import os
import time
import logging
from typing import Optional
from google.adk.models.lite_llm import LiteLlm

logger = logging.getLogger(__name__)

class ModelFactory:
    """ç»Ÿä¸€çš„LLMæ¨¡å‹å·¥å‚ç±»"""
    
    # å…¨å±€æ¨¡å‹é…ç½®
    MODELS_TO_TRY = [
        "Qwen/Qwen3-235B-A22B",
        "deepseek-ai/DeepSeek-V3.1", 
        "deepseek-ai/DeepSeek-R1-0528"
    ]
    
    API_BASE = "https://api-inference.modelscope.cn/v1"
    CUSTOM_LLM_PROVIDER = "openai"
    MAX_RETRIES = 2
    TIMEOUT = 30
    RETRY_DELAY = 2  # seconds
    
    @classmethod
    def create_llm_model(cls, service_name: str = "Unknown") -> Optional[LiteLlm]:
        """
        åˆ›å»ºLiteLLMæ¨¡å‹ï¼Œå¸¦æœ‰å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
        
        Args:
            service_name: è°ƒç”¨æœåŠ¡çš„åç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•
            
        Returns:
            LiteLlmå®ä¾‹æˆ–Noneï¼ˆå¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼‰
        """
        try:
            # è·å–APIå¯†é’¥
            api_key = cls._get_api_key()
            
            # å°è¯•æ¯ä¸ªæ¨¡å‹
            for i, model in enumerate(cls.MODELS_TO_TRY):
                try:
                    logger.info(f"[{service_name}] Attempting to create model: {model} (attempt {i+1}/{len(cls.MODELS_TO_TRY)})")
                    
                    # é…ç½®æ¨¡å‹å‚æ•°
                    model_kwargs = cls._get_model_kwargs(model, api_key)
                    
                    # åˆ›å»ºæ¨¡å‹
                    llm_model = LiteLlm(**model_kwargs)
                    
                    logger.info(f"[{service_name}] âœ… Successfully created model: {model}")
                    return llm_model
                    
                except Exception as e:
                    logger.error(f"[{service_name}] âŒ Failed to create model {model}: {str(e)[:100]}...")
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ¨¡å‹ï¼Œç­‰å¾…åé‡è¯•
                    if model != cls.MODELS_TO_TRY[-1]:
                        logger.info(f"[{service_name}] â­ï¸  Trying next model in {cls.RETRY_DELAY}s...")
                        time.sleep(cls.RETRY_DELAY)
                    continue
            
            # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
            logger.warning(f"[{service_name}] âŒ All model options failed. AI enhancement will be limited.")
            return None
            
        except Exception as e:
            logger.error(f"[{service_name}] âŒ Critical error in model creation: {str(e)}")
            return None
    
    @classmethod
    def _get_api_key(cls) -> str:
        """è·å–APIå¯†é’¥"""
        api_key = os.getenv("MODELSCOPE_API_KEY") or "dummy_key"
        if not os.getenv("MODELSCOPE_API_KEY"):
            logger.warning("MODELSCOPE_API_KEY not found, using dummy key for ModelScope")
        return api_key
    
    @classmethod
    def _get_model_kwargs(cls, model: str, api_key: str) -> dict:
        """è·å–æ¨¡å‹é…ç½®å‚æ•°"""
        model_kwargs = {
            "model": model,
            "api_key": api_key,
            "api_base": cls.API_BASE,
            "custom_llm_provider": cls.CUSTOM_LLM_PROVIDER,
            "max_retries": cls.MAX_RETRIES,
            "timeout": cls.TIMEOUT
        }
        
        # Qwenæ¨¡å‹çš„ç‰¹æ®Šé…ç½®
        if "Qwen" in model:
            logger.info(f"ğŸ”§ Configuring Qwen model {model} with enable_thinking=false")
            model_kwargs["enable_thinking"] = False
        
        return model_kwargs
    
    @classmethod
    def create_model_with_fallback(cls, service_name: str = "Unknown") -> LiteLlm:
        """
        åˆ›å»ºæ¨¡å‹ï¼Œå¦‚æœå¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸ï¼ˆç”¨äºå¿…é¡»æœ‰æ¨¡å‹çš„åœºæ™¯ï¼‰
        
        Args:
            service_name: è°ƒç”¨æœåŠ¡çš„åç§°
            
        Returns:
            LiteLlmå®ä¾‹
            
        Raises:
            RuntimeError: å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
        """
        model = cls.create_llm_model(service_name)
        if model is None:
            raise RuntimeError(f"[{service_name}] All model options failed. Please check your API key and try again later.")
        return model

# ä¾¿æ·å‡½æ•°ï¼Œç”¨äºå‘åå…¼å®¹
def create_llm_model(service_name: str = "Unknown") -> Optional[LiteLlm]:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºLLMæ¨¡å‹"""
    return ModelFactory.create_llm_model(service_name)

def create_model_with_fallback(service_name: str = "Unknown") -> LiteLlm:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºæ¨¡å‹ï¼ˆå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸ï¼‰"""
    return ModelFactory.create_model_with_fallback(service_name)
